{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.feature import ChiSqSelector\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://vaibhavs-mbp:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.5</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>twitter_bot_identification</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1107cea90>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = SparkSession.builder.master(\"local\").appName(\"twitter_bot_identification\").getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading and Cleaning Training Data\n",
    "Source: Kaggle (https://www.kaggle.com/charvijain27/detecting-twitter-bot-data?select=training_data_2_csv_UTF.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[id: decimal(18,0), id_str: string, screen_name: string, location: string, description: string, followers_count: int, friends_count: int, listedcount: int, favourites_count: int, verified: boolean, statuses_count: int, lang: string, default_profile: boolean, default_profile_image: boolean, has_extended_profile: boolean, bot: int]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = spark.read.option(\"quote\", \"\\\"\").option(\"escape\", \"\\\"\")\\\n",
    "        .load(path=\"train_data.csv\",format=\"csv\", sep=\",\", inferSchema=\"true\", header=\"true\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features to detect Twitter Bots:\n",
    "['followers_count', 'friends_count', 'listedcount', 'favourites_count', 'default_profile', 'word <b>'bot'</b> in the screenname <b>or</b> in the description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[screen_name: string, description: string, location: string, followers_count: int, friends_count: int, listedcount: int, favourites_count: int, statuses_count: int, default_profile: boolean, bot: int]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.createOrReplaceTempView('df')\n",
    "raw_df = spark.sql('SELECT screen_name, description, location, followers_count, friends_count, listedcount,\\\n",
    "                        favourites_count, statuses_count, default_profile, bot FROM df WHERE verified = false')\n",
    "raw_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = raw_df.select(\n",
    "'followers_count', 'friends_count', 'listedcount', 'favourites_count', 'statuses_count', 'default_profile','bot',\n",
    "  F.col(\"screen_name\").cast(\"string\").contains(\"bot\").alias(\"screen_name_binary\"),\n",
    "  F.col(\"description\").cast(\"string\").contains(\"bot\").alias(\"description_name_binary\")\n",
    ").withColumn('bot_binary', F.col('screen_name_binary') | F.col('description_name_binary')).fillna({'bot_binary':False})\\\n",
    ".select('bot_binary', 'followers_count', 'friends_count', \n",
    "'listedcount', 'favourites_count', 'statuses_count', 'default_profile','bot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------+-------------+-----------+----------------+--------------+---------------+---+\n",
      "|bot_binary|followers_count|friends_count|listedcount|favourites_count|statuses_count|default_profile|bot|\n",
      "+----------+---------------+-------------+-----------+----------------+--------------+---------------+---+\n",
      "|     false|           1291|            0|         10|               0|         78554|           true|  1|\n",
      "|     false|              1|          349|          0|              38|            31|           true|  1|\n",
      "|      true|           1086|            0|         14|               0|           713|           true|  1|\n",
      "|     false|             33|            0|          8|               0|           676|           true|  1|\n",
      "|     false|             11|          745|          0|             146|           185|          false|  1|\n",
      "|     false|              1|          186|          0|               0|            11|           true|  1|\n",
      "|      true|            193|            0|         19|               0|          6068|          false|  1|\n",
      "|     false|           8227|            2|         89|              26|          2597|           true|  1|\n",
      "|      true|            275|            0|         17|              23|          9922|          false|  1|\n",
      "|     false|             51|            3|          9|               0|          2515|           true|  1|\n",
      "|     false|             51|            1|         12|               0|           111|          false|  1|\n",
      "|      true|              2|            1|          4|               0|           230|           true|  1|\n",
      "|     false|              0|           29|          0|               0|             0|           true|  1|\n",
      "|     false|              1|          206|          0|               0|             0|           true|  1|\n",
      "|     false|              0|           38|          0|               0|             0|           true|  1|\n",
      "|     false|            109|            0|         16|               0|         16067|           true|  1|\n",
      "|     false|            250|            0|         25|               0|         31721|           true|  1|\n",
      "|     false|             15|         1941|          1|             319|           406|          false|  1|\n",
      "|     false|            190|         1899|          0|              27|             0|           true|  1|\n",
      "|      true|            181|            0|         24|               0|         21506|           true|  1|\n",
      "+----------+---------------+-------------+-----------+----------------+--------------+---------------+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scalerizing the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------+\n",
      "|features                             |\n",
      "+-------------------------------------+\n",
      "|[0.0,1291.0,0.0,10.0,0.0,78554.0,1.0]|\n",
      "|[0.0,1.0,349.0,0.0,38.0,31.0,1.0]    |\n",
      "|[1.0,1086.0,0.0,14.0,0.0,713.0,1.0]  |\n",
      "|[0.0,33.0,0.0,8.0,0.0,676.0,1.0]     |\n",
      "|[0.0,11.0,745.0,0.0,146.0,185.0,0.0] |\n",
      "+-------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cols=train_df.columns\n",
    "cols.remove(\"bot\")\n",
    "assembler = VectorAssembler(inputCols=cols,outputCol=\"features\")\n",
    "train_df = assembler.transform(train_df)\n",
    "train_df.select(\"features\").show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_df.randomSplit([0.8, 0.2], seed=12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+\n",
      "|bot|prediction|\n",
      "+---+----------+\n",
      "|  1|       1.0|\n",
      "|  1|       1.0|\n",
      "|  1|       1.0|\n",
      "|  0|       1.0|\n",
      "|  1|       1.0|\n",
      "|  1|       1.0|\n",
      "|  1|       1.0|\n",
      "|  1|       1.0|\n",
      "|  1|       1.0|\n",
      "|  1|       1.0|\n",
      "+---+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(labelCol=\"bot\", featuresCol=\"features\",maxIter=10)\n",
    "lr_model = lr.fit(train)\n",
    "predict_train = lr_model.transform(train)\n",
    "predict_test = lr_model.transform(test)\n",
    "predict_test.select(\"bot\",\"prediction\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn = predict_test.select(\"bot\",\"prediction\").filter(predict_test.bot == 0).filter(predict_test.prediction == 0).count()\n",
    "fp = predict_test.select(\"bot\",\"prediction\").filter(predict_test.bot == 0).filter(predict_test.prediction == 1).count()\n",
    "fn = predict_test.select(\"bot\",\"prediction\").filter(predict_test.bot == 1).filter(predict_test.prediction == 0).count()\n",
    "tp = predict_test.select(\"bot\",\"prediction\").filter(predict_test.bot == 1).filter(predict_test.prediction == 1).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score is:  0.7853403141361258\n"
     ]
    }
   ],
   "source": [
    "recall = tp/(fn+tp)\n",
    "precision = tp/(fp+tp)\n",
    "f1 = (2*recall*precision)/(recall+precision)\n",
    "print(\"F1 Score is: \",f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The area under ROC for train set is 0.8299374078420743\n",
      "The area under ROC for test set is 0.8224646000765415\n"
     ]
    }
   ],
   "source": [
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol='rawPrediction',labelCol='bot')\n",
    "print(\"The area under ROC for train set is {}\".format(evaluator.evaluate(predict_train)))\n",
    "print(\"The area under ROC for test set is {}\".format(evaluator.evaluate(predict_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+\n",
      "|bot|prediction|\n",
      "+---+----------+\n",
      "|  1|       1.0|\n",
      "|  1|       1.0|\n",
      "|  1|       1.0|\n",
      "|  0|       1.0|\n",
      "|  1|       1.0|\n",
      "|  1|       1.0|\n",
      "|  1|       1.0|\n",
      "|  1|       1.0|\n",
      "|  1|       1.0|\n",
      "|  1|       1.0|\n",
      "+---+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(labelCol=\"bot\", featuresCol=\"features\", numTrees=10)\n",
    "rf_model = rf.fit(train)\n",
    "predict_train = rf_model.transform(train)\n",
    "predict_test = rf_model.transform(test)\n",
    "predict_test.select(\"bot\",\"prediction\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn = predict_test.select(\"bot\",\"prediction\").filter(predict_test.bot == 0).filter(predict_test.prediction == 0).count()\n",
    "fp = predict_test.select(\"bot\",\"prediction\").filter(predict_test.bot == 0).filter(predict_test.prediction == 1).count()\n",
    "fn = predict_test.select(\"bot\",\"prediction\").filter(predict_test.bot == 1).filter(predict_test.prediction == 0).count()\n",
    "tp = predict_test.select(\"bot\",\"prediction\").filter(predict_test.bot == 1).filter(predict_test.prediction == 1).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score is:  0.8823529411764706\n"
     ]
    }
   ],
   "source": [
    "recall = tp/(fn+tp)\n",
    "precision = tp/(fp+tp)\n",
    "f1 = (2*recall*precision)/(recall+precision)\n",
    "print(\"F1 Score is: \",f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The area under ROC for train set is 0.9471908759892869\n",
      "The area under ROC for test set is 0.9270091848450059\n"
     ]
    }
   ],
   "source": [
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol='rawPrediction',labelCol='bot')\n",
    "print(\"The area under ROC for train set is {}\".format(evaluator.evaluate(predict_train)))\n",
    "print(\"The area under ROC for test set is {}\".format(evaluator.evaluate(predict_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accessing MongoDB to get real time tweet data from Kafka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pymongo import MongoClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient('localhost:27017')\n",
    "collection = client.bots.bots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: count is deprecated. Use estimated_document_count or count_documents instead. Please note that $where must be replaced by $expr, $near must be replaced by $geoWithin with $center, and $nearSphere must be replaced by $geoWithin with $centerSphere\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1048573"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Bot predictions of the twitter data stored in the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDF(df):\n",
    "    df.createOrReplaceTempView('df')\n",
    "    df = spark.sql('SELECT screen_name, description, CAST(followers_count AS int), CAST(friends_count AS int)\\\n",
    "    , CAST(listedcount AS int), CAST(favourites_count as INT), CAST(statuses_count AS int), default_profile FROM df')\n",
    "    return df.select(\n",
    "    'followers_count', 'friends_count', 'listedcount', 'favourites_count', 'statuses_count', 'default_profile',\n",
    "      F.col(\"screen_name\").cast(\"string\").contains(\"bot\").alias(\"screen_name_binary\"),\n",
    "      F.col(\"description\").cast(\"string\").contains(\"bot\").alias(\"description_name_binary\")\n",
    "    ).withColumn('bot_binary', F.col('screen_name_binary') | F.col('description_name_binary')).fillna({'bot_binary':False})\\\n",
    "    .select('bot_binary', 'followers_count', 'friends_count', \n",
    "    'listedcount', 'favourites_count', 'statuses_count', 'default_profile')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFeatures(train_df):\n",
    "    cols=train_df.columns\n",
    "    assembler = VectorAssembler(inputCols=cols,outputCol=\"features\")\n",
    "    train_df = assembler.transform(train_df)\n",
    "    return train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = {}\n",
    "for element in collection.find({},{\"_id\": 0}):\n",
    "    if element['screen_name'] not in user:\n",
    "        handle = element['screen_name']\n",
    "        location = element['location']\n",
    "        df = getDF(spark.read.json(sc.parallelize([json.dumps(element)])))\n",
    "        featuresDF = getFeatures(df)\n",
    "        predict = lr_model.transform(featuresDF)\n",
    "        if int(predict.select(\"prediction\").first().prediction) == 1:\n",
    "            isBot = True\n",
    "        else:\n",
    "            isBot = False\n",
    "        user[handle] = [location, isBot]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('user.json', 'w') as file:\n",
    "     file.write(json.dumps(user))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Bot percentage:  8.175638434686753 %\n"
     ]
    }
   ],
   "source": [
    "bots = 0\n",
    "nonBots = 0\n",
    "for key in user:\n",
    "    if user[key][1]:\n",
    "        bots += 1\n",
    "    else:\n",
    "        nonBots += 1\n",
    "print(\"Total Bot percentage: \",bots*100/(bots+nonBots),\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete mongo database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collection.drop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
